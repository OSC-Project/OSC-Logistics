#+TITLE:     OSC Update
#+AUTHOR:    A. Jbara, L. Michel, A. Herzberg, J. Breslin
#+EMAIL:     ldm@engr.uconn.edu
#+DATE: \today
#+DESCRIPTION:
#+KEYWORDS:
#+BEAMER_THEME: Berlin
#+BEAMER_COLOR_THEME: beaver
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:https://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+LaTeX_HEADER: \usepackage{minted}
#+LaTeX_HEADER: \usemintedstyle{emacs}
#+LaTeX_HEADER: \newminted{common-lisp}{fontsize=\footnotesize}
#+BEAMER_HEADER: \logo{\includegraphics[height=.9cm]{figures/comcast.png}}
#+LaTeX: \setbeamercolor{myblockcolor}{bg=magenta,fg=white}

#+name: setup-minted
#+begin_src emacs-lisp :exports none
 (setq org-latex-listings 'minted)
     (setq org-latex-custom-lang-environments
           '(
            (emacs-lisp "common-lispcode")
             ))
     (setq org-latex-minted-options
           '(("frame" "lines")
             ("fontsize" "\\scriptsize")
             ("linenos" "")))
     (setq org-latex-to-pdf-process
           '("pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"
             "pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
#+end_src


* CVE Classification
*** Last Time
- Generated monogram(one-word term) and bigram(two-word term) frequency distributions over 34 injection CVE
- Decided relevant terms via distinctness
  - distinct terms = Common in sample, uncommon in random sample
  - Examples: "a", "to"
- Scored relevancy of rest of database by occurence of these terms

*** Frequency Analysis
- Generated frequency distributions over 34 injection CVE
  - yeilded 294 total monograms, 683 total bigrams
- Normalization: eliminate symbols, lingustic stemming, remove stopwords
- Sort by distinctness: (frequency of term in sample set) - (frequency of term in entire set)
- Manually choose most distinct terms that may indicate whether or not a package is relevant to us
#+ATTR_LATEX: :width 5cm
[[./stem.png]]

*** Frequency Analysis cont'd
- Glossary of monogram terms to test on (12): code, execut, arbitrari, inject, command, sqlite,
  shell, sequel, sql, waterlin, postgr, mysql
- Glossary of bigram terms to test on (12): 'arbitrari command', 'command inject',
'inject vulner', 'a command', 'inject in', 'execut arbitrari', 'to execut',
'sequel is', 'sqlite and', 'microsoft sql', 'sql server', 'arbitrari code'
  - Order DOES matter

*** Results From Last Time
- Monogram Relevancy Test:
  - Many entries scored highly, suggesting relevant terms were not specific enough
- Bigram Relevancy Test:
  - Seems more precise(higher relevancy %), but yeilds fewer results
  - Some bigrams never appeared in test set
#+ATTR_LATEX: :width 6cm
[[./figures/bigram-analysis-results.png]]

*** Refining Search Method
- Manually analyze each high-scoring package to determine relevancy
  - Start with Bigram test results, move to monogram tests
  - Relevant CVEs will be added to sample set

*** Example: CVE-2018-3772
- Bigram Relevancy Score: 3
- Entered in Database as CWE-20 (Improper Input Validation)
- This vulnerability indeed leads to a Command Injection attack, as
  mentioned in the description:
#+BEGIN_QUOTE
 "Concatenating unsanitized user input in the `whereis` npm module <
 0.4.1 allowed an attacker to execute arbitrary commands.
 The ~whereis~ module is deprecated and it is recommended to use the `which` npm module instead."
#+END_QUOTE

*** Example: CVE-2019-15657
- Bigram Relevancy Score: 1
- Entered in Database as CWE-20 (Improper Input Validation)
- Modules intended purpose is to let users make eval calls in a
  sandbox, however poor sanitization allows the user to escape and
  execute code.
#+BEGIN_QUOTE
The static-eval module is intended to evaluate statically-analyzable
expressions. In affected versions, untrusted user input is able to
access the global function constructor, effectively allowing arbitrary
code execution.
#+END_QUOTE

*** Bigram Test Summary
- 11 out of 536 packages scored above 0
- Upon manual analysis, 3 of the 11 were found to be relevant to the current development of our tool. The other 8 are not relevant to the current development of our tool.
#+ATTR_LATEX: :width 6cm
[[./figures/bigram_result_distribution.png]]


*** Next Step
 - Continue manual analysis of high scoring CVEs from monogram analysis.
 - Weighting for distiguishing terms.

* LGTM
*** Where We left off
- Expand set of queries for Code Injection
- Analyze the other packages we used the sink finder on
- Consider possible automation of this process.

*** What's New
- Major Advancement in automation for ~CodeQL~
  -Specifically Integrated Fixed Automation for applying queries to packages

*** Before
- Manually pack external JS packages onto your PC
- Manually create a DB for each package
- Manually update each created DB
- Manually run Query(ies) to the DB associated with external JS package
- Manually remove each DB when done

*** Cons:
- Many tedious steps
- Have to remember file locations
- Disk Storage usage goes up quickly
- Not sufficiently scalable
- Not streamlined

*** Now (With Automation)
- Accomplish all these task with one automation script
- Standardize Folder structure
- Disk Management (Store what you only need)
- Automation is scalable
- Streamlined, easier to troubleshoot

*** Automation Usage
- Input (Two arguments) 
  - Package and query (i.e mypackages1.0 myQuery.ql)
  - For multiple packages or queries, specify .json Ext. in arguments (i.e packages.json queries.json)
- Output
  - Three new directories (for external JS packages, CodeQL Databases, and CSV results folder)
  - Results are in a csv file labeled with the specific query and package combination it analyzes
- Can run one query against multiple packages or multiple queries against one package and everything in between

*** Automation Diagram
#+ATTR_LATEX: :width 6cm :height 6cm
[[./figures/AutomationDiagram.png]]

*** Other benefits
- Free up our resources to expand set of queries
- Able to get sinks results(if they exist) faster
- reduce operation time for evaluating query performance

*** Next Steps
- Revise documentation
- Fix edge case bugs
- Verify query results
- Expand sets of queries

* OSC Benchmark

*** Where We Left Off
- Build a JavaScript benchmark library with synthetic examples to mimic OWASP's benchmarks
- Tests are either a true or false positive
- Currently 9 benchmarks
- Automatically generates scorecards

*** What's New
- Working with Kerwin on the LGTM automation script
  - Dowloading and testing tools to our GitHub repo in order to ensure reproducability for everyone
- Integrating LGTM automation script with the scorecard generation script

*** Next Step
- Polish and finish off remaining details

* CVE-ID Registration
*** Where We Left Off
- Emailed ~cve-request@iojs.org~
- Submitted info requesting CVE-IDs for  packages
    - Jade,
    - Depot, and
    - PrototypeJS

*** What's New
- Continuing the process for submitting a CVE-ID request
- Was told to upload information to HackerOne website
- Made 3 reports on HackerOne for each package (Jade, Depot, and PrototypeJS)
- Now waiting for another response

* Summary
*** What We Have Done So Far
- Manual analysis on highest scoring cves
- LGTM automation script for custom queries
- Uploaded CVEs details for submission
*** Questions?
- Questions and Comments?
